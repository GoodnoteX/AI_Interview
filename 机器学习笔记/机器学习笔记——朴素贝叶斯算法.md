> 大家好，这里是好评笔记，公主号：Goodnote，专栏文章私信限时Free。本笔记介绍机器学习中朴素贝叶斯算法。

![在这里插入图片描述](https://github.com/GoodnoteX/Ai_Interview/blob/main/机器学习笔记/image/6.jpg)

---

>@[toc]
---
## 贝叶斯定理（Bayes' Theorem）
贝叶斯定理**用于描述事件之间的条件概率关系，解决分类和间接解决回归问题**。它的
描述了事件 $A$ 在事件 $B$ 发生后的**条件概率**：

$$
P(A | B) = \frac{P(B | A) \cdot P(A)}{P(B)}
$$

在朴素贝叶斯分类中：
- $A$ 表示数据点属于某个类别（如“垃圾邮件”或“正常邮件”）。
- $B$ 表示数据点的特征（如邮件的词频）。
- P(A | B) ：表示在已知**特征 \( B \)** 的情况下，属于类别 \( A \) 的概率（**后验概率**）。
- P(B | A) ：表示在已知**类别 \( A \)** 的情况下，观察到特征 \( B \) 的概率（**条件概率**）。
- P(A) ：事件 A 发生的**先验概率**。
- P(B) ：事件 B 发生的**先验概率**。

贝叶斯定理的核心思想是**通过已知的先验概率和条件概率，计算某个事件的后验概率**。

> 如图像生成时候的CFG（Classifier-Free Guidance）就是使用贝叶斯实现的。
## 朴素贝叶斯分类器（Naive Bayes Classifier）

朴素贝叶斯分类器是基于贝叶斯定理的一种简单而有效的分类算法。它的**核心假设**是在给定目标变量的条件下，**所有特征之间是相互独立的**，即“**条件独立性假设**”。虽然这个假设在**现实中通常不成立**，**但在实际应用中表现得非常好**。

### 计算步骤

1. **计算先验概率**：计算每个类别的先验概率 $P(C_i)$，其中 $C_i$ 表示类别。

2. **计算条件概率/似然概率**：对于每个特征，计算在给定类别的条件下特征出现的概率 $P(x_j | C_i)$。

3. **应用贝叶斯定理**：计算给定样本属于每个类别的后验概率 $P(C_i | x)$，其中 $x$ 是特征向量。

4. **做出分类决策**：选择具有**最高后验概率**的类别作为**分类结果**。

数学表达式为：

$$
P(C_i | x_1, x_2, \dots, x_n) = \frac{P(C_i) \cdot P(x_1 | C_i) \cdot P(x_2 | C_i) \cdots P(x_n | C_i)}{P(x_1, x_2, \dots, x_n)}
$$

在实际应用中，由于分母 $P(x_1, x_2, \dots, x_n)$对所有类别是相同的，所以只需要比较分子部分：

$$
P(C_i) \cdot P(x_1 | C_i) \cdot P(x_2 | C_i) \cdots P(x_n | C_i)
$$

### 优势
1. **计算简单**：因为条件独立假设，计算复杂度低，速度快。
2. **数据需求少**：对小数据集也能表现良好。
3. **处理多类别问题**：适合处理多类别分类问题。

### 局限性
1. **条件独立性假设不现实**：在许多情况下，特征之间并不是独立的，假设不成立时分类器效果可能下降。
2. **对数据格式敏感**：在某些应用场景中，对特征的处理和分布的要求较高。

## 朴素贝叶斯的三种常见变体

根据数据的不同特性，朴素贝叶斯有三种常见的变体模型：高斯朴素贝叶斯、多项式朴素贝叶斯和伯努利朴素贝叶斯。它们分别适用于不同类型的数据和应用场景。

### 1. 高斯朴素贝叶斯（Gaussian Naive Bayes）




> 详细全文请移步公主号：Goodnote。  
参考：[欢迎来到好评笔记（Goodnote）！](https://mp.weixin.qq.com/s/lCcceUHTrM7wOjnxkfrFsQ)
