> 大家好，这里是好评笔记，公主号：Goodnote，专栏文章私信限时Free。本笔记介绍机器学习中常见的决策树算法。

![在这里插入图片描述](https://github.com/GoodnoteX/Ai_Interview/blob/main/机器学习笔记/image/7.png)

> @[toc]
---

## 决策树（Decision Tree）概述

决策树是一种**基于树形结构的机器学习算法，广泛应用于分类和回归任务中**。它通过一系列的规则**将数据集划分为不同的子集**，从而进行分类或预测。决策树算法直观、易于解释，并且能够处理复杂的特征交互。
## 基本概念
- **节点（Node）**：
  - **根节点（Root Node）**：树的起始节点，表示整个**数据集**。
  - **内部节点（Internal Node）**：表示数据集的划分条件，包含**特征和阈值**。
  - **叶节点（Leaf Node）**：表示分类或回归的最终结果，包含**类别标签或连续值**。
- **分支（Branch）——决策规则**：从一个节点到另一个节点的路径。
- **路径（Path）——决策过程**：从根节点到叶节点的序列。
- **深度（Depth）——决策树的复杂度**：从根节点到最深叶节点的最长路径长度。
## 任务类型
决策树既可以用于**分类任务**，也可以用于**回归任务**。
### 分类任务
在分类任务中，决策树用于**将数据划分到不同的离散类别中**。目标是通过一系列条件判断，将数据划分为不同类别，并最终在叶节点上输出类别标签。
- **常用算法（不同的划分特征的标准）**：
  - **ID3**：使用**信息增益**来选择划分特征。
  - **C4.5**：使用**信息增益比**来选择划分特征，并支持连续特征处理。
  - **CART（分类树）**：使用**基尼系数(Gini Index)** 来选择最优划分特征。

- **应用场景**：
  - 电子邮件分类（垃圾邮件识别）。
  - 图像识别（识别不同的物体类别）。
  - 医疗诊断（预测病人的健康状况类别）。

### 回归任务
在回归任务中，决策树**用于预测连续值**。目标是通过一系列的分裂操作，将数据划分成不同的区间，并在每个叶节点上输出一个数值（通常是该节点中所有样本的均值）。
- **常用算法**：
  - **CART（回归树）**：使用**最小化均方误差(Mean Squared Error, MSE)**或其他度量标准来选择最优划分特征。

- **应用场景**：
  - 房价预测（预测某个地区的房屋价格）。
  - 股票市场预测（预测股票的未来价格）。
  - 气象预测（预测某个地点的温度或降雨量）。

### 分类和回归中的差异
分类树（Classification Tree）：
- 输出的是离散类别标签。
- 每个叶节点表示一个类别。
- 划分标准基于分类纯度（如信息增益、基尼系数）。

回归树（Regression Tree）：
- 输出的是连续数值。
- 每个叶节点表示一个数值（如节点样本的均值）。
- 划分标准基于回归误差（如均方误差）。
## 决策树算法的具体实现
### 比较总结

| **算法** | **划分标准** | **支持连续特征** | **处理缺失值** | **树结构** | **优点** | **缺点** | **适用场景** |
|----------|---------------|------------------|----------------|------------|----------|----------|--------------|
| **ID3**  | 信息增益 | 否 | 否 | 多叉树 | 实现简单，适合小规模数据 | 偏向于选择取值多的特征，不能处理连续变量 | 小规模、离散特征数据集 |
| **C4.5** | 信息增益比 | 是 | 是 | 多叉树 | 支持连续特征，能处理缺失值 | 计算复杂度高，生成树较大 | 大规模数据，有连续特征和缺失值的数据 |
| **CART** | 基尼系数 | 是 | 否 | 二叉树 | 适用于分类和回归问题，剪枝方便 | 对噪声数据敏感，容易过拟合 | 分类、回归任务，要求生成二叉树时 |


- **ID3** 适合**小规模**的、**离散**特征的数据集，但**不适合**处理**连续特征和缺失值**。
- **C4.5** 是 ID3 的改进版本，**能处理连续特征、缺失值**，适合处理复杂的大规模数据集。
- **CART** 能同时用于分类和回归任务，生成简洁的**二叉树结构**，但对噪声敏感，适合需要生成二叉树结构的应用场景。

### ID3（Iterative Dichotomiser 3）
#### 原理
- ID3 **通过信息增益（Information Gain）来选择划分特征**，ID3 选择**信息增益最大的特征**进行划分。信息增益表示划分数据集后信息熵的减少程度，熵越小，数据纯度越高。主要用于**分类任务**。




> 详细全文请移步公主号：Goodnote。  
参考：[欢迎来到好评笔记（Goodnote）！](https://mp.weixin.qq.com/s/lCcceUHTrM7wOjnxkfrFsQ)
