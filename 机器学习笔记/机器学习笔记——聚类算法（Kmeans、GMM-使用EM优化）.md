
> 大家好，这里是好评笔记，公主号：Goodnote，专栏文章私信限时Free。本笔记介绍机器学习中常见的聚类算法（Kmeans、GMM-使用EM优化）。

![在这里插入图片描述](https://github.com/GoodnoteX/Ai_Interview/blob/main/机器学习笔记/image/9.png)

---


> @[toc]
---

# 聚类
## K-Means
K-Means 是一种经典的聚类算法，用于**将数据集划分为 K 个簇**，每个簇由其质心（簇中心）表示。算法的目标是**最小化簇内样本点到质心的平方距离之和**，从而使得同一个簇内的样本更加相似。
### 工作原理
1. **选择初始质心**：随机选择 K 个点作为初始质心。
2. **分配样本到最近的质心**：将每个样本分配给距离最近的质心，形成 K 个簇。
3. **更新质心**：重新计算每个簇的质心，即簇内所有样本的平均值。
4. **重复步骤 2 和 3**，直到质心不再变化或达到最大迭代次数。
### 特点
- **优点**：简单易实现，计算速度快，适合大规模数据集。
- **缺点**：对**初始质心敏感，容易陷入局部最优**；**K-Means 基于欧氏距离，通常只能处理球形或凸形簇**。

## K-Medoids
K-Medoids（也称为 **PAM**，Partitioning Around Medoids）是一种基于原型的聚类算法，与 K-Means 类似，但它**选择数据点本身作为质心**（称为 Medoid），**而不是质心的平均值。**
### 工作原理
1. **选择初始 Medoid**：**随机选择 K 个数据点作为初始 Medoid**。
2. **分配样本到最近的 Medoid**：将每个样本分配给距离最近的 Medoid，形成 K 个簇。
3. **更新 Medoid**：在每个簇内选择一个新的数据点，使得该点到簇内所有其他点的距离之和最小。
4. **重复步骤 2 和 3**，直到 Medoid 不再变化或达到最大迭代次数。
> 更新 Medoid如何做：
> 1. 计算每个点的总距离：对于簇内的每个数据点 $x_i$，计算该点到簇内所有其他点的距离之和；
> 2. 选择距离最小的点：找到使得距离之和最小的那个点作为新的 Medoid。
>
>计算量很大
### 特点
- **优点**：**对异常值不敏感**（因为选择实际数据点作为 Medoid），适合非球形簇。
- **缺点**：计算复杂度高，不适合大规模数据集。
## Mini-Batch K-Means
Mini-Batch K-Means 是 K-Means 的一种扩展，旨在提高计算效率和速度。它通过在每次**迭代中使用小批量的随机样本来更新质心，而不是使用整个数据集**。
### 工作原理
1. **选择初始质心**：随机选择 K 个点作为初始质心。
2. **抽取小批量数据**：从数据集中随机抽取一个小批量的数据点。
3. **分配样本到最近的质心**：将小批量数据中的每个样本分配给距离最近的质心。
4. **更新质心**：根据小批量数据更新质心，而不是全量数据。
5. **重复步骤 2 到 4**，直到质心收敛或达到最大迭代次数。
### 特点
- **优点**：计算速度快，内存占用少，适合大规模数据集和在线学习场景。
- **缺点**：相较于 K-Means 可能会损失一些精度，质心的更新不如全量数据集的更新精确。
## K-Means++（重要）
K-Means++ 是 **K-Means 的改进版本**，旨在通过**改进初始质心的选择**来提高聚类效果和算法的稳定性。它能有效**减少 K-Means 对初始质心的敏感性问题**。
### 工作原理
1. **选择第一个质心**：从数据集中随机**选择一个样本点**作为第一个质心。
2. **选择下一个质心**：选择**距离现有质心最远的点作为下一个质心**，选择概率与当前最小距离成正比。
3. **重复步骤 2**，直到选择出 K 个质心。
4. 按照 K-Means 算法的步骤进行聚类。
### 特点
- **优点**：初始质心选择更好，聚类效果更加稳定，收敛速度更快。
- **缺点**：相比 K-Means 增加了一定的计算开销。
## 总结

- **K-Means**：**随机选择 K 个点**作为初始质心。简单高效，适合大多数常见场景，但对初始质心敏感。
- **K-Medoids**：**随机选择 K 个数据点**作为初始 Medoid。适合处理含有异常值或非球形分布的聚类问题，但计算复杂度较高。
- **Mini-Batch K-Means**：**随机选择 K 个点**作为初始质心，**与标准 K-Means 相同**。适合大规模数据和在线学习，速度快，但精度较 K-Means 略有下降。
- **K-Means++**：**质心不是一次选出来的，从数据集中随机选择一个样本点**作为第一个质心，之后**距离现有质心最远的点作为下一个质心**。改进了初始质心的选择，收敛速度更快，效果更稳定。
## K的选值




> 详细全文请移步公主号：Goodnote。  
参考：[欢迎来到好评笔记（Goodnote）！](https://mp.weixin.qq.com/s/lCcceUHTrM7wOjnxkfrFsQ)
