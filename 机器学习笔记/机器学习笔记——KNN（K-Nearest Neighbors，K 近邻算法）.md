
> 大家好，这里是好评笔记，公主号：Goodnote，专栏文章私信限时Free。本笔记介绍机器学习中的 KNN（K-Nearest Neighbors，K 近邻算法）

![在这里插入图片描述](https://github.com/GoodnoteX/Ai_Interview/blob/main/机器学习笔记/image/5.jpg)

---

>@[toc]

---
# 思想
KNN（K-Nearest Neighbors，K 近邻算法）是一种基于实例的**监督学习**算法，广泛应用于**分类和回归任务**中。它的主要思想是：对于给定的样本点，**找到其在特征空间中距离最近的 K 个训练样本，并以这些最近邻的样本的类别或数值来预测该样本的类别或数值**。

# 工作原理
1. **计算距离**：**计算待分类的样本点与所有训练样本点之间的距离**。
2. **选择 K 个最近邻样本**：根据计算出的距离，从训练集中**选择 K 个距离最近的样本**点。
3. **投票或平均**：
   - 对于分类任务，选择这**K 个样本中出现次数最多的类别**作为预测结果。
   - 对于回归任务，取这 **K 个样本的平均值**作为预测结果。

# K 值选择
   - **K 值**是 KNN 算法中的一个**超参数**，表示选择的邻居数量。K 值的选择非常关键：
     - 如果 K 值**过小**（如 K=1），模型可能会**过拟合**，对噪声数据过于敏感。
     - 如果 K 值**过大**，模型可能会**欠拟合**，因为更多的邻居可能会包含不同类别的样本，从而影响分类结果。

## 交叉验证
   - **交叉验证**是选择合适 K 值的常用方法。通过交叉验证，我们可以**尝试多个不同的 K 值**，并通过**在验证集上**的表现（如准确率、F1分数等）来**选择表现最好的 K 值**。
> **步骤**：
> 1. 将训练数据集划分为若干个子集（如 5 折或 10 折交叉验证），每次取其中一个子集作为验证集，剩下的 \( k-1 \) 个子集作为训练集。
> 2. 对于每个候选 K 值，进行 KNN 训练并计算验证集上的预测性能（例如准确率）。
> 3. 选择在交叉验证中性能最佳的 K 值作为最终模型的参数。
## 类似K-means的肘部法
   - 在某些情况下，可以绘制**不同 K 值**下模型的**误差曲线**或**分类错误率曲线**，观察曲线的趋势。当误差随着 K 值减小而急剧下降，然后趋于平缓时，那个转折点（类似“肘部”）的 K 值就是理想的选择。

>**误差曲线**或**分类错误率曲线**：
> - X 轴 表示 K 值（即最近邻的个数）
> - Y 轴 表示 模型的误差值/分类错误率
>
>本质上也是使用类似交叉验证，多个K值验证最好的是哪个值

> **步骤**：
> 1. 选择不同的 K 值，计算每个 K 值下的测试误差。
> 2. 绘制误差随着 K 值变化的曲线。
> 3. 找到误差曲线的拐点，即误差下降速度变缓的地方（通常 K 值稍小的点）。
## 经验选择法/奇数优先
   - 在很多情况下，K 值的选择可以通过经验来做出初步估计，通常选取**较小的奇数值**，如 \( K=3, 5, 7 \)。这样做的目的是避免平票的情况（即 KNN 中相同数量的邻居属于不同类别）。
>   - 对于大多数分类任务，**K 值的初始范围**通常是：
>     - 小规模数据集：**K=3**、**K=5** 或 **K=7** 常常是一个不错的起点。
>     - 大规模数据集：可以选择较大的 K 值，具体取决于数据集的规模和类别分布。
## 加权 KNN
   - 对距离的样本希望赋予不同的权重，可以使用**加权 KNN**。在加权 KNN 中，**距离样本越近的邻居会赋予更高的权重**，常见的权重分配方式是**反比例加权**：

$$\text{Weight}(x_i) = \frac{1}{d(x_i, x)}$$

这种方式在 K 值较大时，能够有效增强模型对近邻样本的关注，避免远离的噪声样本影响分类结果。

# 距离度量
## 欧氏距离（Euclidean Distance）
欧氏距离是**最常用的**距离度量方式，用于度量两个点在 n 维**空间中的直线距离**。它是两个点之间的“直线”距离，表示为：
$$d(x, y) = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}$$
其中：
- $x$ 和 $y$ 表示两个样本点。
- $x_i$ 和 $y_i$ 分别是样本 $x$ 和 $y$ 在第 $i$ 个特征上的取值。
- $n$ 是特征的维度数。
### 特点
- 适合度量**连续数据的距离**。
- **受数据量纲影响较大**，不适用于不同量纲的数据比较。
> 量纲是（如重量、温度、距离等），可以使用**特征缩放（归一化和标准化）**，减少特征之间的量纲差异。

## 曼哈顿距离（Manhattan Distance）

曼哈顿距离也称为**L1 距离**或**城市街区距离** ，它是两个点在 n 维空间中**各维度之差的绝对值之和**。表示为：

$$d(x, y) = \sum_{i=1}^n |x_i - y_i|$$
其中：
- $x$ 和 $y$ 表示两个样本点。
- $x_i$ 和 $y_i$ 分别是样本 $x$ 和 $y$ 在第 $i$ 个特征上的取值。
- $n$ 是特征的维度数。





> 详细全文请移步公主号：Goodnote。  
参考：[欢迎来到好评笔记（Goodnote）！](https://mp.weixin.qq.com/s/lCcceUHTrM7wOjnxkfrFsQ)



