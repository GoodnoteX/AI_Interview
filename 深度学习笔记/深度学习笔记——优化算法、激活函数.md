
> 大家好，这里是好评笔记，公主号：Goodnote，专栏文章私信限时Free。本笔记介绍深度学习中常见的优化算法、激活函数。

![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/95af1c69b68948feaadd7721535f91e4.png#pic_center)


---
@[toc]
# 优化算法
在深度学习中，优化算法用于**调整模型的参数**（如权重和偏置）以**最小化损失函数**。
## 方法
### 梯度下降 (Gradient Descent, GD)
**简介**：  
梯度下降是最基本的优化算法，通过**计算损失函数**相对于模型参数的**梯度**，**沿着梯度下降的方向更新参数**，以最小化损失函数。
- **批量梯度下降（Batch Gradient Descent）**：在每次迭代中**使用整个训练集**计算梯度，计算开销大但收敛稳定。
- **随机梯度下降（Stochastic Gradient Descent, SGD）**：每次迭代**只使用一个样本**计算梯度，效率高，但容易在训练中产生波动。
- **小批量梯度下降（Mini-batch Gradient Descent）**：在每次迭代中**使用一小部分训练集**进行梯度计算，平衡了批量梯度下降和随机梯度下降的优缺点。


**公式：**
$$\theta_{t + 1}=\theta_{t}-\eta \nabla_{\theta} J(\theta_{t})$$

- 其中：
	- $\theta_{t}$表示当前模型的参数，
	- $\eta$是学习率（也称为步长），
	- $\nabla_{\theta} J(\theta_{t})$是参数$\theta_{t}$对于损失函数$J(\theta_{t})$的梯度。


**优点**：
1. **简单直观**：梯度下降的原理简单，计算损失函数的梯度，沿着梯度最速下降方向进行优化。
   
2. **广泛适用**：梯度下降可以应用于各种类型的机器学习问题，包括线性回归、逻辑回归和神经网络等。在许多优化问题中，梯度下降是基本的选择，适用范围广泛。

3. **可扩展性强**：梯度下降可以在不同的规模和复杂度下使用。通过**调整批量大小**（如批量梯度下降、随机梯度下降、小批量梯度下降），可以适应不同数据集的规模。

4. **良好的收敛性**：对于**凸优化问题**，梯度下降可以保证收敛到**全局最优解**。而在**非凸问题**中，梯度下降也能找到**局部最优解**，具有良好的泛化能力。

**缺点**：
1. **收敛速度慢**：梯度下降尤其是**批量梯度下降（Batch Gradient Descent）**，收敛速度慢。在大型数据集上，批量梯度下降的效率较低。

2. **容易陷入局部最优**：在**非凸优化问题**中，梯度下降容易陷入**局部最优解**。

3. **对学习率敏感**：梯度下降依赖于超参数**学习率(learning rate)** 的选择。如果学习率太小，收敛速度非常慢；如果学习率太大，梯度下降可能无法收敛，甚至在训练过程中发散。

4. **梯度消失或梯度爆炸问题**：在深层神经网络中，由于链式法则，梯度值会在反向传播时逐层累积，容易导致梯度消失或梯度爆炸问题，导致网络训练不稳定或无法更新参数。

**适用场景**：
- 适用于数据量较大的场景，如深度学习中的大规模数据训练。
  

### 动量法 (Momentum)
**简介**：  
动量法是对GD的改进，它在更新参数时不仅考虑**当前的梯度**还考虑**前几次的梯度**。这样**就像给参数加上“惯性”** ，从而**避免震荡**。

**公式：**

$$v_{t + 1}=\beta v_{t}+(1 - \beta)\nabla_{\theta} J(\theta_{t})$$
$$\theta_{t + 1}=\theta_{t}-\eta v_{t + 1}$$

- 其中：
	- $v_{t}$ 是动量，表示历史梯度的加权平均，
	- $\beta$ 是动量系数，通常设定为接近1（例如0.9），
	- $\eta$ 是学习率，控制更新步长。

**优点**：
- **更快的收敛速度**：由于动量的存在，它可以在损失函数的谷底处快速收敛。
- **减少震荡**：动量法在梯度方向上能够更稳健，减少梯度震荡现象。

**缺点**：
- **需要调节动量系数**：动量的超参数（通常设为0.9左右）需要精心调节，使用不当可能导致训练失效。

**适用场景**：
- 适用于数据噪声较多或梯度震荡较大的场景，如深度神经网络中使用的卷积层。

---

### AdaGrad (Adaptive Gradient Algorithm)
**简介**：  
AdaGrad是一种**自适应学习率**的方法。它为**每个参数独立调整学习率**，**学习率的调整取决于历史梯度的平方和**，这使得**频繁更新的参数学习率逐渐减小，而较少更新的参数学习率保持较大**。这种方式**防止**了**步长过大导致的震荡**，也**避免**了**步长过小导致的收敛速度慢**。

**公式：**
$$g_{t}=\nabla_{\theta}J(\theta_{t})$$
$$G_{t}=G_{t - 1}+g_{t}^{2}$$
$$\theta_{t + 1}=\theta_{t}-\frac{\eta}{\sqrt{G_{t}+\epsilon}}g_{t}$$
- **其中：**
	- $g_{t}$是在第$t$次迭代中的梯度，
	- $G_{t}$是累积的历史梯度平方和，
	- $\eta$是全局学习率，
	- $\epsilon$是为了避免除以零的小常数（通常取$10^{-8}$）。


**优点**：
- **自适应学习率**：不需要手动调整学习率，适应**稀疏数据**场景。
- **适合稀疏数据**：对于稀疏数据（如NLP任务中的词嵌入学习），AdaGrad表现很好。

**缺点**：
- **学习率过快衰减**：随着训练的进行，累积的梯度**会导致学习率快速减小**，最终学习率趋近于0，难以继续学习。

**适用场景**：
- 适合于稀疏特征的场景，如自然语言处理中的词嵌入或推荐系统中的高维特征。

---
### RMSProp (Root Mean Square Propagation)
**简介**：  
RMSProp 是为了**解决 AdaGrad 中学习率过快衰减的问题**。它引入了**指数加权移动平均（梯度的二阶矩）**来**平滑历史梯度的平方**，使得学习率不会迅速下降。

**公式：**
$$g_{t}=\nabla_{\theta} J(\theta_{t})$$

$$E[g_{t}^{2}]_{t}=\gamma E[g_{t - 1}^{2}]+(1 - \gamma)g_{t}^{2}$$

$$\theta_{t + 1}=\theta_{t}-\frac{\eta}{\sqrt{E[g_{t}^{2}]_{t}+ \epsilon}}g_{t}$$

- 其中：
	- $E[g_{t}^{2}]_{t}$ 是梯度平方的指数加权移动平均，
	- $\gamma$ 是平滑系数，通常设为0.9，
	- $\eta$ 是学习率，控制更新幅度。


**优点**：
- **学习率调整更稳健**：通过指数加权平均处理梯度，RMSProp 可以更好地适应复杂且多变的损失面。
- **解决AdaGrad的衰减问题**：与AdaGrad相比，它能够维持适当的学习率，使得训练能持续有效进行。

**缺点**：
- **需要调节超参数**：RMSProp中的超参数，如移动平均系数，可能需要手动调整以取得最佳效果。

**适用场景**：
- 适用于非平稳目标或在线学习场景，如强化学习中的Q-Learning。

---
### Adam (Adaptive Moment Estimation)
**简介**：  
Adam **结合了动量法和RMSProp的优点** ，既使用**动量法来考虑历史梯度**，也通过**RMSProp来自适应调整学习率**。它既利用了梯度的一阶矩（动量），又利用了梯度的二阶矩（RMSprop）。
> - **一阶矩（First Moment）**：通常指**梯度的均值**，即梯度的期望值。它反映了**梯度的方向和大小**。
> - **二阶矩（Second Moment）**：通常指**梯度的方方差“ 或 “平方均值”**，即**梯度的平方的均值/期望值**。它反映了**梯度变化的幅度或不确定性**。


**公式：**
Adam同时结合了动量法和RMSProp的思想，使用了梯度的一阶矩和二阶矩的移动平均。
1. 计算梯度：$g_{t}=\nabla_{\theta} J(\theta_{t})$
2. 计算梯度的一阶矩估计（动量）和二阶矩估计：
   - $m_{t}=\beta_{1} m_{t - 1}+(1 - \beta_{1})g_{t}$
   - $v_{t}=\beta_{2} v_{t - 1}+(1 - \beta_{2})g_{t}^{2}$
     - 其中，$\beta_{1}$和$\beta_{2}$是控制一阶和二阶矩的衰减率，通常取0.9和0.999。
3. 进行偏差修正：
   - $\hat{m}_{t}=\frac{m_{t}}{1-\beta_{1}^{t}}$
   - $\hat{v}_{t}=\frac{v_{t}}{1-\beta_{2}^{t}}$
4. 更新参数：$\theta_{t + 1}=\theta_{t}-\frac{\eta}{\sqrt{\hat{v}_{t}+ \epsilon}}\hat{m}_{t}$


**优点**：
- **收敛速度快**：Adam在大多数情况下表现出良好的收敛性，能够加速模型的训练。
- **自适应学习率**：每个参数都有独立的学习率，不需要太多的手动调参。
- **鲁棒性**：在各种问题上都表现良好，适用于大多数深度学习任务。

**缺点**：
- **可能过早收敛**：Adam在某些场景下可能会收敛到亚最优解。
- **需要额外的超参数**：Adam的β1、β2以及学习率等超参数需要调整，可能影响训练效果。

**适用场景**：
- 适用于大多数深度学习任务，尤其是在梯度更新频繁且噪声较大的场景，如图像分类、语言模型训练等。
---
### AdamW 优化算法
**简介**
Adam 优化算法的改进版本，专门针对**优化正则化过程中的权重衰减问题**。传统的 Adam 将权重衰减作为正则化的一部分，而 AdamW 通过将权重衰减与梯度更新过程分离，提供了更准确的正则化效果。
> 权重衰减（Weight Decay） 是一种用于正则化的技术，主要目的是防止模型过拟合。它通过在损失函数中添加一个与参数大小相关的惩罚项，来限制模型参数的大小，使得模型的权重不能无限增大。

**流程：**

1. 计算梯度：$g_{t}=\nabla_{\theta} J(\theta_{t})$
2. 计算一阶矩动量和二阶矩：
   - $$m_{t}=\beta_{1} \cdot m_{t - 1}+(1 - \beta_{1}) \cdot g_{t}$$
   - $$v_{t}=\beta_{2} \cdot v_{t - 1}+(1 - \beta_{2}) \cdot g_{t}^{2}$$
3. 偏差修正：
   - $$\hat{m}_{t}=\frac{m_{t}}{1 - \beta_{1}^{t}}$$
   - $$\hat{v}_{t}=\frac{v_{t}}{1 - \beta_{2}^{t}}$$
4. 更新参数（带权重衰减项）：
   - $$\theta_{t + 1}=\theta_{t}-\eta \cdot\left(\frac{\hat{m}_{t}}{\sqrt{\hat{v}_{t}+\epsilon}}+\lambda \cdot \theta_{t}\right)$$

这就是AdamW的完整公式，它在Adam的基础上通过引入权重衰减项，增强了正则化效果。



> **AdamW** 的公式与 **Adam** 的主要区别就在于第四步的**参数更新**。因此，**只需要在第四步**添加权重衰减项 $\lambda \cdot \theta_t$ 即可。AdamW 的其他部分，如梯度计算、一阶矩、二阶矩和偏差修正，和 Adam 是完全相同的。

**优点**
- **更好的正则化效果**：AdamW 将**权重衰减**与**梯度更新** **分离**，能够实现更精确的正则化，**减少过拟合**。
- **与 Adam 兼容**：保留了 Adam 的所有优势，如自适应学习率和动量计算，同时修正了正则化问题。
- **更快的收敛**：由于正则化效果更准确，模型能够更好地收敛，尤其是在复杂网络中。
- **广泛适用**：适用于许多深度学习任务，特别是需要进行正则化的任务，如计算机视觉、自然语言处理等领域。

**缺点**
- **超参数更多**：与 Adam 相比，AdamW 增加了一个权重衰减超参数\( $\lambda$ \)，因此需要调试的超参数更多，调参复杂度增加。
- **计算复杂度略高**：与 Adam 相比，虽然整体计算复杂度没有显著增加，但在包含权重衰减的场景下，其计算量稍有增加。

**使用场景**
- **深度神经网络中的正则化**：适用于在深度学习模型中加入正则化以避免过拟合的场景，例如在大规模数据集上进行训练时，AdamW 能更好地控制权重更新。
- **计算机视觉任务**：如图像分类、目标检测等任务，AdamW 可以通过有效的正则化提升模型的泛化能力。
- **自然语言处理（NLP）**：在语言模型、文本分类等任务中，AdamW 的正则化效果能使模型在复杂数据集上更好地训练。
- **需要长时间训练的任务**：AdamW 在长时间训练任务中的表现通常比 Adam 更好，因为其优化的正则化可以避免模型随着时间过拟合。

### 总结

| **算法**   | **原理**                                                                                      | **优点**                                       | **缺点**                                    | **适用场景**                          |
|------------|-----------------------------------------------------------------------------------------------|------------------------------------------------|---------------------------------------------|---------------------------------------|
| **GD**    | 梯度下降算法，通过每次使用**整个训练集**，	或者**SGD和MGD**。  **计算损失函数相对于模型参数的梯度**，**沿着梯度下降**的方向更新参数，以最小化损失函数。   | 理论稳定，易于实现	                   | 计算成本高，特别是在大数据集上更新缓慢	                           | 小规模数据集或批量处理场景             |
| **Momentum**| 在 SGD 基础上增加**动量**，不仅考虑当前的梯度，还利用**过去的梯度积累**，加入**惯性**来加速收敛并**减少震荡**。                              | 提升收敛速度、减少震荡                        | 需调节动量系数                               | 数据噪声较多的场景                   |
| **AdaGrad**| 对**每个参数**采用**不同的学习率**，**自适应学习率**，并**根据历史梯度的平方和自动调整每个参数的学习率**。                        | 自适应学习率，适合稀疏数据                     | **学习率快速衰减**                              | **稀疏特征**数据场景                     |
| **RMSProp**| 在 **AdaGrad 基础上**，通过**引入梯度的二阶矩**来平衡学习率的更新，**解决**了 AdaGrad **学习率快速衰减的问题**。     | 学习率调整更稳健，解决 AdaGrad 衰减问题        | 需调节超参数                                | 非平稳目标、强化学习                 |
| **Adam**   | 结合了 **Momentum 和 RMSProp**，采用**自适应学习率和动量**来更新参数，适应性强，收敛速度快。  利用了梯度的**一阶矩**（动量），又利用了梯度的**二阶矩**（RMSprop）。            | 收敛快，适应性强，鲁棒性好                     | 可能过早收敛，需调整多个超参数               | 大多数深度学习任务，图像分类、语言模型 |
| **AdamW**  | 改进的 Adam 算法，结合**权重衰减正则化**，将**权重衰减**与**梯度更新**过程**分离**，解决过拟合。           | 改进的正则化，避免权重衰减导致的过拟合问题     | 增加超参数调试复杂度                        | 正则化场景，如图像分类、NLP任务       |

1. **GD（Gradient Descent，梯度下降）**：每次迭代使用整个数据集计算梯度，并更新模型参数，确保模型稳步收敛，但在大数据集上计算成本高且更新缓慢。
2. **SGD（Stochastic Gradient Descent）**：每次参数更新只使用**一个或小批量**样本进行计算，虽然计算效率高，但更新不稳定，容易出现震荡。
3. **Momentum**：通过在每次梯度更新时引入**动量**，动量会**积累之前梯度的方向**，帮助加速收敛，减少震荡。适合噪声较多的数据。
4. **AdaGrad**：**自适应调整学习率**，梯度较大的参数学习率变小，适合处理稀疏数据，但学习率在训练后期可能过小，导致收敛缓慢。
5. **RMSProp**：在 AdaGrad 基础上引入**滑动平均（梯度的二阶矩）的机制**，使学习率更新更加稳健，避免学习率过快衰减。常用于强化学习或非平稳目标。
6. **Adam**：**结合了 Momentum 和 RMSProp 的优势**，采用自适应学习率和动量机制，使其在大多数深度学习任务中表现良好，收敛快且鲁棒性好。
7. **AdamW**：在 Adam 的基础上，**改进了权重衰减的方式**，通过权重衰减的正则化防止模型过拟合，特别适用于需要正则化的任务，如图像分类和 NLP。

这使得每种优化算法在处理不同的任务时，能够根据具体的需要选择合适的优化方式。

---
## 经验和实践建议
训练模型时，**结合不同优化方法**和策略来提高模型性能的常见做法。接下来，我会详细解释每个策略和概念背后的原理及其作用。

### 使用 Adam 进行初始训练，之后用 SGD 进行微调
**作用**：
- 结合了 **Adam 的快速收敛能力** 和 **SGD 的精细调整能力**，Adam 用于快速收敛，而 SGD 用于微调，能够快速训练模型并进一步优化模型，使其参数更接近全局最优。

**解释**：
- **Adam** 是一种自适应学习率优化算法，能够**在早期阶段快速收敛**。由于 Adam 能够**自适应地调整每个参数的学习率**，这使得 Adam 能够帮助模型尽快接近局部最优解。
  
- **SGD** 则被认为在**局部微调时表现得更为稳定**。尽管收敛速度较慢，但在接近最优解时，SGD 具有更好的优化全局性能的能力。使用 SGD 可以细致地调整模型参数，使其更加接近全局最优。
	
**其他**：
- **RMSProp + SGD**：自适应学习率算法RMSProp 可以迅速找到损失函数的低谷（能很好地处理非平稳数据），可以用于在线学习或强化学习中。然后通过 SGD 进一步优化模型参数。
### 冷启动策略（Cold Start Strategy）
**作用**：
- **帮助模型快速找到一个初始的较好参数**，避免一开始陷入局部最优，进而提高后续优化阶段的效果。

**解释**：
- 冷启动策略主要解决的是**训练初期**时，如何**合理地设置参数、超参数以及模型结构**，确保训练能够顺利进行，并尽快进入有效的学习阶段。
- **初始模型参数初始化**或者**初始优化器选择错误** ，导致模型一开始的训练进展缓慢，甚至收敛到较差的局部最优解。采用冷启动策略，即开始时使用较大批量、较高学习率或者自适应学习率优化算法（如 Adam）进行初始训练，以帮助模型快速找到一个可行的参数区域。
 
- 然后，再使用更稳健的优化方法（如 SGD）以及更小的学习率来进行进一步的训练，从而细化参数并找到更接近全局最优的解。
---

### 大批量与小批量交替训练
**作用**：
- **交替使用大批量和小批量训练**，可以在一定程度上结合两者的优势：用**小批量训练来加速模型的训练**，同时用**大批量训练来稳定模型**，并帮助模型在更广的参数空间探索。

**解释**：
- **小批量（mini-batch）** 对数据集的一部分进行更新来避免计算整个数据集的梯度，从而**加速模型的训练**。然而，小批量训练有时可能会陷入局部最优解。

- **大批量训练** 则能够**更稳定地更新梯度**，因为它使用更多的数据，减小了梯度中的噪声。但大批量训练的缺点是训练速度较慢。
---

### 学习率逐步衰减（Learning Rate Decay）

**作用**：
- **学习率衰减** 可以让模型在**训练初期，使用较高的学习率**进行快速探索，在**后期逐渐减小学习率**进行更精细的调整，从而帮助模型更加稳定地收敛到全局最优解。


**解释**

- **小学习率的优缺点**
  - **优点**：
**精细调整、避免震荡、适合后期微调**：小学习率能够使模型在接近最优解时进行更细致的参数调整。能**避免震荡**，使模型更加平稳地优化。在模型训练的后期，小学习率能够帮助模型更精确地逼近全局最优。
  - **缺点**：
**收敛速度慢、可能陷入局部最优**：小学习率会导致参数更新幅度较小，因此模型的收敛速度较慢，特别是在训练初期时。由于更新幅度较小，模型可能会陷入局部最优解，难以跳出并探索更优的解。

---

- **大学习率的优缺点**
  - **优点**：
**收敛速度快、跳出局部最优**：大学习率可以使模型在训练初期迅速调整参数，快速探索参数空间，帮助模型尽快接近局部最优解。较大的参数更新幅度有助于模型摆脱局部最优，探索更优的解。

  - **缺点**：
**容易震荡或发散、难以精细调整**：在接近最优解时，大学习率可能导致参数更新幅度过大，导致模型在局部区域内反复跳跃，甚至发散，无法收敛。大学习率使模型的参数更新过于粗糙，难以在训练后期进行精细优化。

**总结**
- **小学习率**：适合训练的后期，帮助模型精细调整参数、稳定收敛。**更容易过拟合**。
- **大学习率**：适合训练初期，帮助模型快速探索参数空间、提高收敛速度。**更容易欠拟合**。

常见的学习率衰减策略包括：
1. **指数衰减**：学习率按照某个指数函数衰减；
2. **阶梯衰减**：在训练的某些阶段手动减小学习率；
3. **自适应衰减**：当模型的损失停止下降时，自动减小学习率。
### 总结

将 **Adam 和 SGD** 结合使用，以及通过 **冷启动策略、大批量与小批量交替训练** 和 **学习率逐步衰减**，能够有效提升深度学习模型的训练效率和性能。Adam 初期的快速收敛可以节省时间和资源，而 SGD 的精细优化能力可以确保最终结果更接近全局最优。让模型在**训练初期，使用较高的学习率**进行快速探索，在后期逐渐减小学习率**进行更精细的调整**，从而帮助模型更加稳定地收敛到全局最优解。


## 主要考虑的参数

以下是选择优化器时需要重点关注的几个关键参数：

### 学习率（Learning Rate, $\eta$）

**描述**：
- 学习率决定了**每次更新参数的步长**，是最重要的超参数之一。**学习率过大**可能导致模型在训练过程中发散，**无法收敛，更容易欠拟合**；**学习率过小**则会导致模型训**练速度缓慢，甚至陷入局部最优，更容易过拟合**。
  
**选择标准**：
- 对于大多数优化器，学习率是必调的参数。常见的做法是**从较大的学习率开始逐步衰减**，或者使用**自适应学习率算法（如 Adam）**。学习率也可以与学习率衰减机制结合使用，在训练过程中逐步降低。

**影响**：
- 大学习率通常加快收敛速度，但可能不稳定，可能导致欠拟合；
- 小学习率则更稳定，但速度较慢，可能导致过拟合。
- 使用太高或太低的学习率都可能导致模型性能不佳。

### 动量（Momentum, $\beta$）

**描述**：
- 动量是用来**加速梯度下降方向**并**减少更新抖动的参数**，通常用于动量法。它通过**引入梯度的历史信息，使得模型参数更新方向更平滑，减少震荡**。
  
**选择标准**：
- 动量的典型**取值范围在0.9到0.99之间**。这个参数决定了历史梯度对当前梯度的影响，**值越大，历史梯度的影响越大**。

**影响**：
- 动量能够**提高模型收敛速度**，特别是在损失函数面比较复杂时有助于跳出局部极小值。但如果动量参数过大，可能导致模型更新过程中的震荡。

### 自适应学习率参数（如 Adam 的 $\beta_1$, $\beta_2$）

**描述**：
- 自适应优化器（如 Adam、RMSProp）会对每个参数**动态调整学习率**。这些优化器通常有**两个主要的超参数 $\beta_1$ 和 $\beta_2$ ，分别控制一阶和二阶矩估计的衰减率**。  
  - $\beta_1$：控制梯度的动量，一般取 0.9；
  - $\beta_2$：控制梯度平方的动量，通常取 0.999。

**选择标准**：
- 默认情况下，$\beta_1 = 0.9$ 和 $\beta_2 = 0.999$ 通常是一个不错的起点，适合大多数任务。但是在特殊任务中，可能需要调节这些参数以更好地控制学习率调整过程。

**影响**：
- $\beta_1$ 和 $\beta_2$ 主要影响 Adam 等优化器的**稳定性和自适应能力**。
- **$\beta_1$ 过大**：动量积累过强，模型更新滞后。
- **$\beta_1$ 过小**：动量作用弱化，导致更新震荡。
- **$\beta_2$ 过大**：自适应学习率变化过慢，优化器调整迟缓。
- **$\beta_2$ 过小**：自适应学习率波动大，优化过程不稳定。

### 批量大小（Batch Size）

**描述**：
- 批量大小决定了每次参数更新时使用的数据样本数量。**小批量（mini-batch）能引入噪声**，帮助模型**跳出局部最优**；**大批量**训练能让模型**更稳定地收敛**。

**选择标准**：
- 通常情况下，批量大小与优化器配合使用。**小批量训练能使模型在参数空间中更充分地探索**，而**大批量训练有助于加速收敛过程**。常见的批量大小在**32、64、128**等，根据计算资源和模型大小进行调整。

**影响**：
- 较小的批量大小能够帮助模型**避免陷入局部最优解**，但训练速度较慢，可能导致欠拟合；
- 较大的批量大小会使梯度估计更精确，**从而使模型稳定**，但可能收敛到局部最优，可能导致过拟合。

### 梯度裁剪（Gradient Clipping）

**描述**：
- 在某些任务（如序列生成任务、循环神经网络中），**梯度爆炸**问题会导致参数更新幅度过大。梯度裁剪是一种**控制梯度最大值的方法，避免梯度爆炸**。

**选择标准**：
- 在梯度可能会爆炸的场景（如长序列建模、循环神经网络中），通常会设置梯度裁剪的阈值，如**5.0 或1.0**，以防止梯度过大。裁剪后，梯度的 L2 范数会限制在指定的阈值内。

**影响**：
- 梯度裁剪可以防止梯度更新过大，导致模型参数发散，尤其适合用于梯度不稳定的任务中。

### 权重衰减（Weight Decay, $\lambda$）

**描述**：
- 权重衰减是一种**正则化技术**，通过在每次梯度更新时直接**对权重参数乘以一个小于 1 的因子，从而限制权重的增长**。从而减少参数的值，**避免过拟合**。

**选择标准**：
- $\lambda$（权重衰减系数）的典型取值通常是 $10^{-4}$到 $10 ^{-6}$之间。权重衰减的选择主要依赖于数据集的规模、模型复杂度以及是否存在过拟合。

**影响**：
- 适度的权重衰减可以有效防止模型过拟合，但过大的权重衰减会导致模型欠拟合。

**说明**：
- **SGD 优化器中**：可以直接使用 L2 正则化或者权重衰减，两者效果几乎相同。
- **Adam 优化器中**：建议使用 **AdamW**，因为它将权重衰减与正则化分离，使得模型训练更稳定、优化过程更合理。

### 初始化参数（Weight Initialization）

**描述**：
- 权重初始化对优化过程至关重要，因为不恰当的初始化会导致训练速度变慢，甚至无法收敛。常见的初始化方法包括：
  - **随机初始化**
  - **Xavier 初始化**
  - **He 初始化**
  - **常数初始化**。
  
参考：[深度学习——评估指标、权重初始化、梯度消失和梯度爆炸](https://lichuachua.blog.csdn.net/article/details/142588940)

**影响**：
- **良好的初始化** 能加速模型的收敛，并使得梯度在前向传播和反向传播时不会过快缩小或膨胀，尤其是在深层神经网络中非常重要。
- **不当的初始化** 可能会导致训练过程中出现梯度消失或梯度爆炸现象，从而导致网络收敛困难或训练时间极长。


在选择优化器的过程中，参数初始化的策略至关重要。以下是一些常见的选择方案：

1. **Xavier 初始化**：适用于 Sigmoid 和 Tanh 激活函数，防止梯度爆炸或消失。
2. **He 初始化**：适用于 ReLU 和其变种激活函数的网络，如深度卷积神经网络（CNN）。
3. **LeCun 初始化**：适用于 SELU 激活函数，尤其是在自归一化神经网络中效果良好。
4. **Orthogonal 初始化**：特别适用于 RNNs 和深层神经网络。
5. **常数初始化**：所有权重被设置为相同的值，常用于偏置项的初始化。

### 总结

在选择优化器的过程中，关键是根据具体任务的需求来确定 **学习率、动量、自适应参数、批量大小** 等参数。同时，诸如 **权重衰减、梯度裁剪** 和 **计算开销** 等因素也必须纳入考量，以确保模型能够在有效的计算资源和时间范围内实现最佳性能。

最常见的策略是先使用自适应学习率优化器（如 Adam）快速收敛，然后用 SGD 进一步微调参数，以达到更好的全局优化效果。同时合理设置学习率衰减等机制，进一步提高训练效果。

---
# 激活函数
激活函数是核心组件之一，它**赋予神经网络非线性能力**，使得模型**能够学习复杂的模式和函数映射**。常见的激活函数有多种，每种激活函数都有其独特的特性、优缺点，并且往往是基于前一代激活函数的改进。
### 1) Sigmoid 函数

**公式：**
$$f(x)=\frac{1}{1 + e^{-x}}$$
**输出范围：**
$$ 0 < f(x)< 1 $$


**优点**：
- **平滑输出**：Sigmoid 函数将输入压缩到 **[0, 1]** 之间，输出可以解释为概率，特别适合用于**二分类问题的输出层**。
  
**缺点**：
- **梯度消失问题**：当输入过大或过小时，Sigmoid 的梯度接近 0，导致梯度消失，特别是在深层网络中，训练效率大大降低。
- **非零中心**：输出是非零中心的，这可能导致后续层的梯度更新不均衡。

**适用场景**：
- 用于 **输出层**，特别是二分类任务中，输出可以解释为概率值。
- 在现代深层网络中，Sigmoid 逐渐被其他激活函数替代，因为它的**梯度消失**问题限制了其在深层网络中的表现。
### 2) Tanh 函数

**公式：**
$$ f(x)=\tanh(x)=\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}} $$
**输出范围：**
$$-1 \leq f(x) \leq 1 $$


**优点**：
- **零中心输出**：与 Sigmoid 函数相比，Tanh 函数的输出在 **[-1, 1]** 之间，输出接近 0 时，使得正负输入在更新时的方向性保持一致，收敛更快。
- **平滑性**：类似 Sigmoid，它具有平滑的输出，在二分类问题中能产生强有力的激活效果。

**缺点**：
- **梯度消失问题**：尽管 Tanh 的输出范围比 Sigmoid 更宽，但仍然会出现梯度消失的问题，尤其是在输入值非常大或非常小时。

**基于 Sigmoid 的改进**：
- Tanh 是对 Sigmoid 函数的改进，通过将输出范围调整为[-1, 1]，**零中心输出**，使得网络能够更好地处理负值，并**避免部分梯度不均衡问题**。 

**适用场景**：
- 在 **隐藏层** 中用于信号标准化和处理负数数据。特别**适合需要中心化输出的场景**，但在深层网络中仍存在梯度消失问题。

### 3) ReLU（Rectified Linear Unit）
**公式：**
$$ f(x)=\max(0,x) $$
**输出范围：**
$$0\leqslant f(x)<+\infty $$


**优点**：
- **计算简单**：ReLU 是线性**分段**函数，计算简单高效，不需要复杂的指数计算。
- **减轻梯度消失问题**：由于 ReLU 在 x > 0 的区间上保持梯度恒定为 1，避免了梯度消失问题，尤其在深层网络中表现优异。
- **稀疏性**：ReLU 的输出是稀疏的，当输入为负值时输出为 0，这有助于网络在某些场景下提升效率。

**缺点**：
- **死亡神经元、Dying ReLU问题**：当 ReLU 的输入为负值时，神经元的输出会一直为 0，导致某些神经元永远不会被激活，进而无法参与模型的学习。
- **不对称性**：ReLU 只对输入的正值产生作用，负值部分被置为 0，导致某些场景下信息丢失。

**基于 Tanh 的改进**：
- ReLU 是一种非线性激活函数，但在设计上**简化了 Tanh 和 Sigmoid 的复杂性**，同时**减轻了梯度消失**的问题。

**适用场景**：
- 深度神经网络的 **隐藏层** 中使用最广泛的激活函数，特别适用于卷积神经网络（CNN）和全连接网络（FCN）。
### 4) Leaky ReLU

**公式：**
$$f(x)=\begin{cases}x & \text{if } x > 0\\\alpha x & \text{if } x\leqslant0\end{cases} $$
其中$\alpha$通常是一个小的正数（如0.01）。
**输出范围：**
$$ -\infty < f(x)<+\infty$$

**优点**：
- **解决死亡神经元、Dying ReLU 问题**：Leaky ReLU 在 x<=0 的区间上引入了一个**小的【固定的】负斜率**，避免了 ReLU 函数的死神经元问题。
- **梯度流动**：通过允许负值的输入产生非零梯度，模型可以更好地更新权重。

**缺点**：
- **不一定总是比 ReLU 更好**：虽然 Leaky ReLU 解决了死神经元的问题，但是**引入了负值的输出**，可能对模型效果有微小的**影响**，在某些任务中，它并不总是比 ReLU 有显著优势。

**基于 ReLU 的改进**：
- Leaky ReLU 是 ReLU 的改进版，通过为负值输入保留一个小的斜率来**避免 ReLU 中的神经元失活问题**。

**适用场景**：
- 常用于深层神经网络中，需要避免死神经元问题时。Leaky ReLU 的负斜率可以帮助梯度有效传播，特别适合于 **生成对抗网络（GANs）** 和 **RNN** 等需要更稳定梯度流的场景。
### 5) Parametric ReLU（PReLU）

**公式：**
$$f(x) = \begin{cases} 
x & \text{if } x > 0 \\
\alpha x & \text{if } x \leq 0 
\end{cases}$$
其中$\alpha$是可学习的参数。

**输出范围：**
$$(-\infty, +\infty)$$
- 由于PReLU在正值区间输出$x$，而在负值区间输出$\alpha x$，且$\alpha$可以是任何常数，因此PReLU的输出范围是从$-\infty$到$+\infty$。


**优点**：
- **可学习的斜率**：与 Leaky ReLU 不同，PReLU 中的 **$\alpha$ 是通过训练学习的**，而不是一个固定值，这使得模型能够自动调整负值部分的斜率。
- **提升模型性能**：**它可以动态适应每个神经元的输入**，在一些深层网络中，比固定的 ReLU 或 Leaky ReLU 表现更好。

**缺点**：
- **增加了模型复杂度**：PReLU 引入了额外的参数 $\alpha$，这增加了模型的复杂性和训练成本。

**基于 Leaky ReLU 的改进**：
- PReLU 是对 Leaky ReLU 的改进，使得负斜率 $\alpha$ 不再固定，而是通过学习调整，以便模型在训练过程中更加灵活。

**适用场景**：
- 适用于 **深度卷积神经网络（CNN）** 和 **其他大型深度网络**，当模型需要更大的灵活性和动态调整时，PReLU 提供了更优的性能。

### 6) ELU（Exponential Linear Unit）

**公式：**
$$f(x) = \begin{cases} 
x & \text{if } x > 0 \\
\alpha(e^x - 1) & \text{if } x \leq 0 
\end{cases}$$
其中$\alpha > 0$是一个超参数，通常取$\alpha = 1$。

**输出范围：**
$$(-\alpha, +\infty)$$
- 当$x > 0$时，ELU输出$x$，所以输出范围可以趋近于$+\infty$。
- 当$x \leq 0$时，ELU的输出是$\alpha(e^x - 1)$，因此下限是$-\alpha$，这取决于$\alpha$的值（通常$\alpha > 0$）。

**优点**：
- **平滑负值处理**：ELU 在 x<=0 时平滑输出，使得负值部分的输出更为柔和，解决了 ReLU 和 Leaky ReLU 在负值区间的突变问题。
- **零中心输出**：相比 ReLU，ELU 的输出更接近零，有助于梯度均衡更新，提升训练速度。
  
**缺点**：
- **计算复杂度高**：ELU 的负值部分包含指数计算，比 ReLU 和 Leaky ReLU 的计算复杂度更高。
  
**基于 ReLU 的改进**：
- ELU 是对 ReLU 的改进，它解决了 ReLU 处理负值时的过度稀疏问题，并通过指数函数使负值部分**更平滑**。

**适用场景**：
- ELU 常用于深层网络，如 **卷积神经网络（CNN）**，尤其是需要更平滑输出的场景。它的平滑负值处理在一定程度上提高了模型的鲁棒性。

### 7) SELU（Scaled Exponential Linear Unit）

**公式：**
$$f(x) = \lambda \begin{cases} 
x & \text{if } x > 0 \\
\alpha(e^x - 1) & \text{if } x \leq 0 
\end{cases}$$
其中：
- $\alpha \approx 1.67326$
- $\lambda \approx 1.0507$

**输出范围：**
$$(-\infty, +\infty)$$


**优点**：
- **自归一化**：SELU 激活函数的最大特点是具有自归一化（self-normalizing）特性，它能够使得神经元的输出保持零均值和单位方差，即便经过多层网络传递后，仍然保持这种归一化效果。这一特性有助于避免梯度消失和梯度爆炸问题。
- **消除梯度消失和爆炸**：SELU 通过引入缩放因子 \($\lambda$\) 和 \($\alpha$\)，在负值区域引入非线性并进行归一化处理，有效防止梯度消失和爆炸。
- **无需额外正则化**：SELU 可以减少或完全消除对批归一化（Batch Normalization）等正则化方法的依赖，在某些场景中表现非常稳定。

**缺点**：
- **依赖特定初始化和架构**：SELU 要发挥最大效果，**必须搭配 LeCun 正态初始化**（LeCun Normal Initialization）和 Alpha Dropout。这种依赖特定初始化和架构的特性使得 SELU 在某些情况下的灵活性较差。
- **对输入数据敏感**：SELU 要求输入数据标准化，即数据需要经过归一化处理（零均值、单位方差），否则效果可能较差。

**基于 ELU 的改进**：
- SELU 是对 ELU 函数的改进，**保留了 ELU 在负值区间的平滑处理**，同时通过**添加缩放因子使输出具有自归一化特性**。这种自归一化特性使得神经网络更稳定，并且减轻了对批归一化等正则化手段的需求。

**适用场景**：
- **自归一化神经网络（SNNs）**：SELU 常用于自归一化神经网络，它可以减少梯度消失和爆炸问题，尤其适用于深层网络。
- 适合需要高度稳定的训练过程，并且对批归一化等方法不适合的场景，如某些 **序列生成** 或 **生成对抗网络（GANs）** 中，SELU 可以提高网络的训练稳定性。
### 8) Swish(SiLU)

**公式：**
$$f(x) = \frac{x}{1 + e^{-x}} = x \cdot \sigma(x)$$
其中$\sigma(x)$是Sigmoid函数。

**优点**：
- **平滑且非单调**：Swish 是一个**非单调**的函数（即它既有递增区间，也有递减区间），这有助于捕捉复杂的非线性特性。
- **更好的性能**：Swish 在一些任务中表现出优于 ReLU 和其他常见激活函数的性能，尤其是在深层网络中。
  
**缺点**：
- **计算复杂度略高**：相比 ReLU，Swish 由于**引入了 Sigmoid 计算**，其计算复杂度稍高。

**基于 ReLU 的改进**：
- Swish 是一种由 Google 提出的激活函数，它**保留了 ReLU 的线性部分**，但**结合了 Sigmoid 的平滑性**，特别适用于深层神经网络。

**适用场景**：
- **深度卷积神经网络（CNN）** 和 **Transformer** 等模型中，Swish 在一些任务（如图像分类、目标检测）中表现优异，特别适合深度模型。
- SD模型的三个组件中都用到了，GSC部件中的S。

### 总结

| 激活函数       | 优点                                               | 缺点                                                | 适用场景                                  |
|----------------|----------------------------------------------------|-----------------------------------------------------|-------------------------------------------|
| **Sigmoid**    | 平滑输出，适合二分类问题                           | 梯度消失，非零中心                                  | 二分类输出层                              |
| **Tanh**       | 零中心输出，平滑                                   | 梯度消失                                            | 中间层或输出层                            |
| **ReLU**       | 计算简单，减轻梯度消失                             | 死神经元问题，不对称输出                            | 深层网络，特别是卷积神经网络（CNN）       |
| **Leaky ReLU** | 解决 ReLU 死神经元问题，保持梯度流动               | 不一定总是比 ReLU 更好                              | 需要避免死神经元问题的深层网络            |
| **PReLU**      | 可学习的负斜率，灵活性高                           | 增加了模型的复杂度和训练时间                        | 深度卷积网络等大型模型                    |
| **ELU**        | 平滑负值处理，零中心输出                           | 计算复杂度高                                        | 需要平滑负值处理的深层网络                |
| **SELU**       | 自归一化，减轻梯度消失和爆炸，减少对正则化的依赖   | 依赖特定的初始化和数据标准化                        | 自归一化神经网络（SNN），深度网络         |
| **Swish**      | 非单调，性能好                                     | 计算复杂度略高                                      | 深层网络，如图像分类和目标检测             |


每种激活函数有其适用场景，选择激活函数时，应根据任务的特性、模型结构以及计算资源综合考虑。
- ReLU 和其变种在现代神经网络中应用广泛；
- Swish 和 ELU 在某些深层网络中表现更优。
- SELU 激活函数的最大优势在于其自归一化特性，适合深度神经网络的训练，尤其是在批归一化不适用的场景中表现优异。



# 历史文章
## 机器学习

[机器学习笔记——损失函数、代价函数和KL散度](https://blog.csdn.net/haopinglianlian/article/details/143831958?)
[机器学习笔记——特征工程、正则化、强化学习](https://blog.csdn.net/haopinglianlian/article/details/143832118?)
[机器学习笔记——30种常见机器学习算法简要汇总](https://blog.csdn.net/haopinglianlian/article/details/143832321)
[机器学习笔记——感知机、多层感知机(MLP)、支持向量机(SVM)](https://blog.csdn.net/haopinglianlian/article/details/143832552)
[机器学习笔记——KNN（K-Nearest Neighbors，K 近邻算法）](https://blog.csdn.net/haopinglianlian/article/details/143832692)
[机器学习笔记——朴素贝叶斯算法](https://blog.csdn.net/haopinglianlian/article/details/143832781?)
[机器学习笔记——决策树](https://blog.csdn.net/haopinglianlian/article/details/143834363)
[机器学习笔记——集成学习、Bagging（随机森林）、Boosting（AdaBoost、GBDT、XGBoost、LightGBM）、Stacking](https://blog.csdn.net/haopinglianlian/article/details/143834494?)
[机器学习笔记——Boosting中常用算法（GBDT、XGBoost、LightGBM）迭代路径](https://blog.csdn.net/haopinglianlian/article/details/143834628)
[机器学习笔记——聚类算法（Kmeans、GMM-使用EM优化）](https://blog.csdn.net/haopinglianlian/article/details/143834707)
[机器学习笔记——降维](https://blog.csdn.net/haopinglianlian/article/details/143834847)
