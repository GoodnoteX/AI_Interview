
> 大家好，这里是好评笔记，公主号：Goodnote，专栏文章私信限时Free。本笔记介绍深度学习中两个重要的模型：AE、VAE。
> 


![在这里插入图片描述](https://github.com/GoodnoteX/Ai_Interview/blob/main/深度学习笔记/image/10.png)


> @[toc]

# 自编码器（Autoencoder, AE）
**论文：** 无标志性论文，最初可以追溯到20世纪80年代和90年代初的神经网络研究。有一个系统性的综述：[Autoencoders](https://arxiv.org/pdf/2003.05991)

**自编码器**是一种**无监督学习**模型，主要**用于数据的降维、特征提取或数据去噪**。它由两个主要部分组成：
![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/4208bc21237b4b70b73fa8d0fe64a78d.png)

1. **编码器（Encoder）**：**将输入数据压缩成低维的隐藏表示**（即编码），这一部分负责从原始数据中**提取特征**。假设输入是 $X$，编码器的**目标是找到一种映射** $f(X) = Z$，其中 $Z$ 是低维空间的表示。

2. **解码器（Decoder）**：**将低维的隐藏表示还原回原始数据的近似值**，解码器试图从编码 Z 中重建输入 X。这一部分的映射是$g(Z) = \hat{X}$，其中$\hat{X}$是还原后的数据。


**训练过程：**$X -> Z -> \hat{X}$，基于无标签数据，通过反向传播和梯度下降来更新编码器和解码器的权重。

**目标**：让重构的$\hat{X}$ 尽量接近输入$X$，即**最小化** **重构误差**（通常**采用均方误差 MSE 或其他损失函数**）。


**优点：**
- 可以用于数据降维，类似于 PCA，但更适合处理非线性数据。
- 用于图像去噪、异常检测等任务。
  
**缺点：**
- 学到的低维表示可能对生成新样本的能力有限，只是压缩信息，而**不具备对输入数据的生成建模能力**。
- 通常不适合处理概率问题，无法给出潜在变量的分布信息。

由上可知，AE的意义在于：
1. **数据降维：** 模型训练结束后，我们就可以认为$Z$编码囊括了输入数据$X$的大部分信息，也因此我们可以直接利用$Z$表达原始数据。
2. **数据重建：** 解码器只需要输入某些有表征信息的编码$Z$（非随机噪声），就能够输出高维的图片数据$\hat{X}$。

> 能否把解码器模型直接当做生成模型，用于**新图像的生成（非重建）**，在低维空间中随机生成某些向量z，再喂给解码器f(z)来生成图片呢？
> - 理论上可以这么做，但问题在于绝大多数随机生成的低维向量$Z$，都是没有意义的噪声，之所以如此，原因在于**没有显性的对的分布进行建模**，我们并不知道哪些能够生成有用的图片。
> - VAE(自变分编码器，Variational Autoencoders)则是在AE的基础上，**显性的对 $Z$ 的分布 $p(z)$ 进行建模**(比如符合某种常见的概率分布)，使得自编码器成为一个合格的生成模型。

# 变分自编码器（Variational Autoencoder, VAE）详解


> 详细全文请移步公主号：Goodnote。  
参考：[欢迎来到好评笔记（Goodnote）！](https://mp.weixin.qq.com/s/lCcceUHTrM7wOjnxkfrFsQ)
